{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE FOLLOWING CODE IS USED FOR PRE-PROCESSING EVENT FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    #print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "#print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new_orig.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. NoSQL Database Project with Apache Cassandra. \n",
    "\n",
    " The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is completed:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to a Cassandra instance on local machine \n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster(['127.0.0.1'])\n",
    "\n",
    "# Instantiate session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEYSPACE CREATED\n"
     ]
    }
   ],
   "source": [
    "# Create Cassandra KEYSPACE\n",
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS sparkify\n",
    "    WITH REPLICATION = \n",
    "    { 'class': 'SimpleStrategy', 'replication_factor' :1}\"\"\"\n",
    ")\n",
    "    print(\"KEYSPACE CREATED\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEYSPACE SET\n"
     ]
    }
   ],
   "source": [
    "#Setting KEYSPACE to the keyspace specified above\n",
    "try:\n",
    "    session.set_keyspace('sparkify')\n",
    "    print(\"KEYSPACE SET\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries created below provide insight into the following data questions. \n",
    "\n",
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Create Schema and table that will provide artist, song title, and song's length in the music app history heard during \\\n",
    "## sessionId = 338, and itemInSession = 4\n",
    "query = \"CREATE TABLE IF NOT EXISTS artist_sessions\"\n",
    "query = query + \"(sessionID int, itemInSession int, artist text, song text, length double,  PRIMARY KEY(sessionId, itemInSession))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Open and iterate through event csv file. \n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "## Create insert query\n",
    "        query = \"INSERT INTO artist_sessions(sessionID, itemInSession, artist, song, length )\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s)\"\n",
    "        ## Assign column elements for each column in the INSERT statement.\n",
    "        session.execute(query, (int(line[8]), int(line[3]),line[0], line[9], int(float(line[5])) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toggleable": false,
    "ulab": {
     "buttons": {
      "ulab-button-toggle-0d963ec4": {
       "style": "primary"
      }
     }
    }
   },
   "source": [
    "#### Query below extracts artist, song, and length based on a provided sessionId and itemInSession. \n",
    "#### Since the query is based on the sessionId and itemInSesson, the composite key is comprised of those columns.  The optimal approach to partioning the data is to partion the data based on the sessionId, and then cluster/sort based on itemInSession values for more efficent querying of the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Execute select statement used to model table.\n",
    "query = \"select artist, song, length from artist_sessions where sessionId = 338 and itemInSession = 4\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate and print out query results.\n",
    "#for row in rows:\n",
    "#    print(row.artist,row.song, row.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      artist                             song  length\n",
      "0  Faithless  Music Matters (Mark Knight Dub)   495.0\n"
     ]
    }
   ],
   "source": [
    "#Create pandas DataFrame for results\n",
    "d = []\n",
    "\n",
    "for row in rows:\n",
    "    d.append((row.artist,row.song, row.length)) \n",
    "\n",
    "d = pd.DataFrame(d, columns = ['artist','song','length'])\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Schema and table that will provide name of artist, song (sorted by itemInSession) and user (first and last name)\\\n",
    "## for userid = 10, sessionid = 182\n",
    "query = \"CREATE TABLE IF NOT EXISTS user_library\"\n",
    "query = query + \"(userId int, sessionId int, artist text, song text, firstName text, lastName text, \\\n",
    "itemInSession int, PRIMARY KEY((userId, sessionId), song, itemInSession))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Open and iterate through event csv file. \n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "## Create insert query\n",
    "        query = \"INSERT INTO user_library(userId, sessionId, artist, song, firstName, lastName, itemInSession)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        ## Assign column elements for each column in the INSERT statement.\n",
    "        session.execute(query, (int(line[10]), int(line[8]),line[0], line[9], line[1], line[4], int(line[3])))\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query below extracts artist, song, and userId based on a given userId and sessionId. \n",
    "#### Since the query is based on the userId and sessionId, the composite key includes those columns. the song and itemInSession data are also included in the composite key, so that song data can be sorted by the itemInSession values.  The optimal approach to partioning the data is to partion the data based on the userId, and then cluster/sort based on sessionId values for more efficent querying of the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute select statement used to model table.\n",
    "query = \"select artist, song, userId from user_library where userId=10 and sessionId =182\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate and print out query results.\n",
    "#for row in rows:\n",
    "#    print(row.artist,row.song, row.userid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              artist                                               song  \\\n",
      "0      Lonnie Gordon  Catch You Baby (Steve Pitron & Max Sanna Radio...   \n",
      "1       Three Drives                                        Greece 2000   \n",
      "2   Down To The Bone                                 Keep On Keepin' On   \n",
      "3  Sebastien Tellier                                          Kilometer   \n",
      "\n",
      "   userId  \n",
      "0      10  \n",
      "1      10  \n",
      "2      10  \n",
      "3      10  \n"
     ]
    }
   ],
   "source": [
    "#Create pandas DataFrame for results\n",
    "c = []\n",
    "\n",
    "for row in rows:\n",
    "    c.append((row.artist,row.song, row.userid)) \n",
    "\n",
    "c = pd.DataFrame(c, columns = ['artist','song','userId'])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Schema and table that will provide every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "query = \"CREATE TABLE IF NOT EXISTS song_user_assoc\"\n",
    "query = query + \"(song text, userId int, artist text, firstName text, lastName text, PRIMARY KEY(song, userId))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and iterate through event csv file. \n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "## Create insert query\n",
    "        query = \"INSERT INTO song_user_assoc(song,  userId, artist, firstName, lastName)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s)\"\n",
    "        ## Assign column elements for each column in the INSERT statement.\n",
    "        session.execute(query, (line[9],  int(line[10]), line[0], line[1], line[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query below extracts user first and last name based on a song they have played. \n",
    "#### Since the query is based on the song, the composite key is comprised of  song and userId so that the data can be be partitoned and sorted efficiently.  For this data the song is he partion key, and the data is then clustered/sorted based on userId.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute select statement used to model table.\n",
    "query = \"select firstName, lastName from song_user_assoc where song = 'All Hands Against His Own'\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate and print out query results.\n",
    "#for row in rows:\n",
    "#    print(row)\n",
    "#    print(row.firstName, row.lastName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    firstName lastName\n",
      "0  Jacqueline    Lynch\n",
      "1       Tegan   Levine\n",
      "2        Sara  Johnson\n"
     ]
    }
   ],
   "source": [
    "#Create pandas DataFrame for results\n",
    "e = []\n",
    "\n",
    "for row in rows:\n",
    "    e.append((row.firstname,row.lastname)) \n",
    "\n",
    "e = pd.DataFrame(e, columns = ['firstName','lastName'])\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist_sessions table dropped\n",
      "user_library table dropped\n",
      "song_user_assoc table dropped\n"
     ]
    }
   ],
   "source": [
    "## Drop tables prior to closing out sessions\n",
    "query = \"drop table artist_sessions\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "    print(\"artist_sessions table dropped\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "query = \"drop table user_library\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "    print(\"user_library table dropped\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "query = \"drop table song_user_assoc\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "    print(\"song_user_assoc table dropped\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shutdown Sessions\n",
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
